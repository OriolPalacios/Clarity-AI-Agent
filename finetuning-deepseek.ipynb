{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11025810,"sourceType":"datasetVersion","datasetId":6866113}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install unsloth\n!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:30:35.208653Z","iopub.execute_input":"2025-03-14T03:30:35.208901Z","iopub.status.idle":"2025-03-14T03:33:50.696280Z","shell.execute_reply.started":"2025-03-14T03:30:35.208880Z","shell.execute_reply":"2025-03-14T03:33:50.695289Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Modules for fine-tuning\nfrom unsloth import FastLanguageModel\nimport torch # Import PyTorch\nfrom trl import SFTTrainer # Trainer for supervised fine-tuning (SFT)\nfrom unsloth import is_bfloat16_supported # Checks if the hardware supports bfloat16 precision\n# Hugging Face modules\nfrom huggingface_hub import login # Lets you login to API\nfrom transformers import TrainingArguments # Defines training hyperparameters\nfrom datasets import load_dataset # Lets you load fine-tuning datasets\n# Import weights and biases\nimport wandb\n# Import kaggle secrets\nfrom kaggle_secrets import UserSecretsClient","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:34:11.317829Z","iopub.execute_input":"2025-03-14T03:34:11.318109Z","iopub.status.idle":"2025-03-14T03:34:40.732042Z","shell.execute_reply.started":"2025-03-14T03:34:11.318087Z","shell.execute_reply":"2025-03-14T03:34:40.731202Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n🦥 Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Load keys for W&B and HuggingFace","metadata":{}},{"cell_type":"code","source":"# Initialize Hugging Face & WnB tokens\nuser_secrets = UserSecretsClient() # from kaggle_secrets import UserSecretsClient\nhugging_face_token = user_secrets.get_secret(\"Hugging_Face_Token\")\nwnb_token = user_secrets.get_secret(\"wnb\")\n\n# Login to Hugging Face\nlogin(hugging_face_token) # from huggingface_hub import login\n\n# Login to WnB\nwandb.login(key=wnb_token) # import wandb\nrun = wandb.init(\n    project='Fine-tune-DeepSeek-R1-Distill-Llama-8B on Clarity Dataset for Clarity-AI-Agent', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:36:18.015717Z","iopub.execute_input":"2025-03-14T03:36:18.016088Z","iopub.status.idle":"2025-03-14T03:36:30.407510Z","shell.execute_reply.started":"2025-03-14T03:36:18.016049Z","shell.execute_reply":"2025-03-14T03:36:30.406863Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moriol_palacios\u001b[0m (\u001b[33moriol_palacios-universidad-nacional-de-san-antonio-abad-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250314_033624-swo4v5iy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/oriol_palacios-universidad-nacional-de-san-antonio-abad-/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Clarity%20Dataset%20for%20Clarity-AI-Agent/runs/swo4v5iy' target=\"_blank\">cookies-n-cream-pastry-1</a></strong> to <a href='https://wandb.ai/oriol_palacios-universidad-nacional-de-san-antonio-abad-/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Clarity%20Dataset%20for%20Clarity-AI-Agent' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/oriol_palacios-universidad-nacional-de-san-antonio-abad-/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Clarity%20Dataset%20for%20Clarity-AI-Agent' target=\"_blank\">https://wandb.ai/oriol_palacios-universidad-nacional-de-san-antonio-abad-/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Clarity%20Dataset%20for%20Clarity-AI-Agent</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/oriol_palacios-universidad-nacional-de-san-antonio-abad-/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Clarity%20Dataset%20for%20Clarity-AI-Agent/runs/swo4v5iy' target=\"_blank\">https://wandb.ai/oriol_palacios-universidad-nacional-de-san-antonio-abad-/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Clarity%20Dataset%20for%20Clarity-AI-Agent/runs/swo4v5iy</a>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# Loading Deepseek and the tokenizer","metadata":{}},{"cell_type":"code","source":"# Set parameters\nmax_seq_length = 2048 # Define the maximum sequence length a model can handle (i.e. how many tokens can be processed at once)\ndtype = None # Set to default \nload_in_4bit = True # Enables 4 bit quantization — a memory saving optimization \n\n# Load the DeepSeek R1 model and tokenizer using unsloth — imported using: from unsloth import FastLanguageModel\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"unsloth/DeepSeek-R1-Distill-Llama-8B\",  # Load the pre-trained DeepSeek R1 model (8B parameter version)\n    max_seq_length=max_seq_length, # Ensure the model can process up to 2048 tokens at once\n    dtype=dtype, # Use the default data type (e.g., FP16 or BF16 depending on hardware support)\n    load_in_4bit=load_in_4bit, # Load the model in 4-bit quantization to save memory\n    token=hugging_face_token, # Use hugging face token\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:39:29.002385Z","iopub.execute_input":"2025-03-14T03:39:29.002691Z","iopub.status.idle":"2025-03-14T03:39:54.304802Z","shell.execute_reply.started":"2025-03-14T03:39:29.002671Z","shell.execute_reply":"2025-03-14T03:39:54.303878Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.3.10: Fast Llama patching. Transformers: 4.49.0.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0982ef1c6ea43118ee354e204731da3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ca04fee63d34b408fd9e29f5e768cda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/53.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fc6fc84fb6249ac90b2eac2957ec723"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"772561054bd14e689c5c2003907f4a36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4915d667e17b4822b1fc3d116c5d9052"}},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Fine tuning the model","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Set a system prompt\n\n```python\ntrain_prompt_style = \n\"\"\"\nBelow is an instruction describing a task. First analyze the technical requirements, then provide a secure Clarity-specific solution.\n\n### Instruction:\nYou are a Clarity blockchain engineer with 5+ years experience. Your answers must, follow Clarity's deterministic principles, prevent common vulnerabilities, use official documentation\n\n### Question:\n{}\n\n### Response:\n<think>\n{}\n</think>\n{}\"\"\n\n```","metadata":{}},{"cell_type":"code","source":"train_prompt_style = \"\"\"Below is an instruction describing a task. First analyze the technical requirements, then provide a secure Clarity-specific solution.\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nYou are a Clarity blockchain engineer with 5+ years experience. Your answers must, follow Clarity's deterministic principles, prevent common vulnerabilities, use official documentation\n\n### Question:\n{}\n\n### Response:\n<think>\n{}\n</think>\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:43:45.627954Z","iopub.execute_input":"2025-03-14T03:43:45.628312Z","iopub.status.idle":"2025-03-14T03:43:45.633215Z","shell.execute_reply.started":"2025-03-14T03:43:45.628286Z","shell.execute_reply":"2025-03-14T03:43:45.632420Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Step 2: Upload the fine tuning dataset","metadata":{}},{"cell_type":"code","source":"import os\nos.listdir('/kaggle/input/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:54:12.764504Z","iopub.execute_input":"2025-03-14T03:54:12.764785Z","iopub.status.idle":"2025-03-14T03:54:12.771103Z","shell.execute_reply.started":"2025-03-14T03:54:12.764764Z","shell.execute_reply":"2025-03-14T03:54:12.770133Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['dataset-v4-augmented']"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import pandas as pd\ndataset = pd.read_csv('/kaggle/input/dataset-v4-augmented/Dataset-v4-augmented.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:56:17.255427Z","iopub.execute_input":"2025-03-14T03:56:17.255741Z","iopub.status.idle":"2025-03-14T03:56:17.309155Z","shell.execute_reply.started":"2025-03-14T03:56:17.255718Z","shell.execute_reply":"2025-03-14T03:56:17.308505Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token  # Define EOS_TOKEN which the model when to stop generating text during training\nEOS_TOKEN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T03:57:02.448627Z","iopub.execute_input":"2025-03-14T03:57:02.448932Z","iopub.status.idle":"2025-03-14T03:57:02.455406Z","shell.execute_reply.started":"2025-03-14T03:57:02.448911Z","shell.execute_reply":"2025-03-14T03:57:02.454590Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'<｜end▁of▁sentence｜>'"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"def format_row(row):\n    return train_prompt_style.format(row[\"Question\"], row[\"CoT\"], row[\"Response\"]) + EOS_TOKEN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T04:11:24.667078Z","iopub.execute_input":"2025-03-14T04:11:24.667330Z","iopub.status.idle":"2025-03-14T04:11:24.672043Z","shell.execute_reply.started":"2025-03-14T04:11:24.667310Z","shell.execute_reply":"2025-03-14T04:11:24.671132Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"from datasets import Dataset\ndataset_df = dataset.copy()\ndataset_df[\"text\"] = dataset_df.apply(format_row, axis=1)\n\ndataset_finetune = Dataset.from_pandas(dataset_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T04:12:04.009313Z","iopub.execute_input":"2025-03-14T04:12:04.009631Z","iopub.status.idle":"2025-03-14T04:12:04.054203Z","shell.execute_reply.started":"2025-03-14T04:12:04.009606Z","shell.execute_reply":"2025-03-14T04:12:04.053581Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"dataset_finetune['text'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T04:12:07.018824Z","iopub.execute_input":"2025-03-14T04:12:07.019121Z","iopub.status.idle":"2025-03-14T04:12:07.035555Z","shell.execute_reply.started":"2025-03-14T04:12:07.019100Z","shell.execute_reply":"2025-03-14T04:12:07.034840Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"'Below is an instruction describing a task. First analyze the technical requirements, then provide a secure Clarity-specific solution.\\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n\\n### Instruction:\\nYou are a Clarity blockchain engineer with 5+ years experience. Your answers must, follow Clarity\\'s deterministic principles, prevent common vulnerabilities, use official documentation\\n\\n### Question:\\nCreate a detailed Clarity smart contract for the Stacks blockchain that implements a decentralized lending protocol allowing users to deposit STX tokens, borrow against their collateral, and earn yield. The contract should include functionality for managing deposits with user-specific balances, implementing a loan system with dynamic interest calculations based on block height, and distributing yield to depositors. Incorporate a 50% loan-to-value ratio limit, a 10% interest rate, and proper error handling for various scenarios including excessive borrowing and repayment issues. Include comprehensive read-only functions for querying user balances and outstanding loan amounts, and ensure all STX transfers are handled securely using the appropriate contract-based transaction patterns. Provide detailed comments explaining the purpose and functionality of each data structure and function in the contract.\\n\\n### Response:\\n<think>\\nI\\'ll generate a detailed Chain-of-Thought explaining the reasoning process behind the Clarity smart contract implementation.\\n\\nLet\\'s start by understanding what we need to build: a decentralized lending protocol on the Stacks blockchain with STX tokens as the primary asset. The core functionality requires deposit management, borrowing against collateral, loan processing, and yield distribution.\\n\\nFirst, the data structure design. The contract needs to track two primary types of data: deposits and loans. For deposits, a map structure is used to associate user principals (blockchain addresses) with their deposit amounts. This approach provides user-specific accounting while maintaining the simplicity needed for a lending protocol. Similarly, loans are tracked with a separate map associating borrowers with both their loan amounts and the block height of their last interaction, which is crucial for interest calculations.\\n\\nNext, global state variables are defined. The total-deposits tracks the aggregate deposits in the contract, which is necessary for calculating proportional yields. The pool-reserve holds accumulated interest payments, effectively serving as the yield source for depositors. The loan-interest-rate is set at 10% as specified in the requirements.\\n\\nError constants are defined to handle various failure scenarios, providing clear feedback to users when operations fail. This follows best practices for smart contract development where error handling is crucial for security and user experience.\\n\\nMoving to the functional implementation, the deposit function allows users to add STX to the contract. It uses stx-transfer? to move tokens from the user to the contract, updates the user\\'s balance in the deposits map, and increases the total-deposits counter. The function uses a combination of let bindings and map operations to manage state transitions safely.\\n\\nThe borrow function implements the 50% loan-to-value ratio requirement. It calculates the allowed borrowing limit based on half the user\\'s deposit (/ user-deposit u2), ensuring users can\\'t borrow more than 50% of their collateral value. Before issuing new loans, it calculates any accrued interest on existing loans using the calculate-accrued-interest private function. The function then updates the loan record with the new total and the current block height for future interest calculations.\\n\\nFor repayments, the repay function first calculates the total amount due including accrued interest. It then ensures users don\\'t overpay, transfers the repayment amount to the contract, and updates the loan record. Importantly, it adds the interest portion to the pool-reserve, making it available for yield distribution.\\n\\nThe claim-yield function distributes accumulated interest to depositors proportionally based on their share of the total deposits. This implements the yield earning requirement in the original specification. The calculation (/ (* (var-get pool-reserve) user-deposit) (var-get total-deposits)) determines each user\\'s fair share of the yield.\\n\\nThe read-only functions get-balance-by-sender, get-balance, and get-amount-owed provide transparency, allowing users to query their current positions and obligations without modifying the contract state. This supports the requirement for comprehensive query functions.\\n\\nFinally, the calculate-accrued-interest private function implements the dynamic interest calculation based on block height as required. It determines the elapsed time in blocks since the last loan interaction and calculates interest proportionally. The calculation (/ (* principal (var-get loan-interest-rate) elapsed-blocks) u10000) applies the 10% interest rate over the elapsed blocks.\\n\\nWait, there seems to be an error in the borrow function. The new-loan calculation is incomplete - it only adds the amount without including the existing loan or accrued interest. This might lead to incorrect loan accounting.\\n\\nOverall, the implementation adheres to the required functionality: deposits with user-specific balances, a loan system with dynamic interest calculations, yield distribution, a 50% loan-to-value ratio, a 10% interest rate, and comprehensive error handling. The contract includes both the required functionality and the necessary read-only functions for querying balances and loan amounts.\\n</think>\\n;; Define the contract\\'s data variables\\n\\n;; Maps a user\\'s principal address to their deposited amount.\\n(define-map deposits { owner: principal } { amount: uint })\\n\\n;; Maps a borrower\\'s principal address to their loan details: amount and the last interaction block.\\n(define-map loans principal { amount: uint, last-interaction-block: uint })\\n\\n;; Holds the total amount of deposits in the contract, initialized to 0.\\n(define-data-var total-deposits uint u0)\\n\\n;; Represents the reserve funds in the pool, initialized to 0.\\n(define-data-var pool-reserve uint u0)\\n\\n;; The interest rate for loans, represented as 10% (out of a base of 100).\\n(define-data-var loan-interest-rate uint u10) ;; Representing 10% interest rate\\n\\n;; Error constants for various failure scenarios.\\n(define-constant err-no-interest (err u100))\\n(define-constant err-overpay (err u200))\\n(define-constant err-overborrow (err u300))\\n\\n;; Public function for users to deposit STX into the contract.\\n;; Updates their balance and the total deposits in the contract.\\n(define-public (deposit (amount uint))\\n    (let (\\n        ;; Fetch the current balance or default to 0 if none exists.\\n        (current-balance (default-to u0 (get amount (map-get? deposits { owner: tx-sender }))))\\n        )\\n        ;; Transfer the STX from sender = \"ST1PQHQKV0RJXZFY1DGX8MNSNYVE3VGZJSRTPGZGM\" to recipient = \"ST1PQHQKV0RJXZFY1DGX8MNSNYVE3VGZJSRTPGZGM.stx-defi (ie: contract identifier on the chain!)\".\\n        (try! (stx-transfer? amount tx-sender (as-contract tx-sender)))\\n        ;; Update the user\\'s deposit amount in the map.\\n        (map-set deposits { owner: tx-sender } { amount: (+ current-balance amount) })\\n        ;; Update the total deposits variable.\\n        (var-set total-deposits (+ (var-get total-deposits) amount))\\n        ;; Return success.\\n        (ok true)\\n    )\\n)\\n\\n;; Public function for users to borrow STX based on their deposits.\\n(define-public (borrow (amount uint))\\n    (let (\\n        ;; Fetch user\\'s deposit or default to 0.\\n        (user-deposit (default-to u0 (get amount (map-get? deposits { owner: tx-sender }))))\\n        ;; Calculate the maximum amount the user is allowed to borrow. (which will be upto HALF of what they deposited)\\n        (allowed-borrow (/ user-deposit u2))\\n        ;; Fetch current loan details or default to initial values.\\n        (current-loan-details (default-to { amount: u0, last-interaction-block: u0 } (map-get? loans tx-sender )))\\n        ;; Calculate accrued interest on the current loan.\\n        (accrued-interest (calculate-accrued-interest (get amount current-loan-details) (get last-interaction-block current-loan-details)))\\n        ;; Calculate the total amount due including interest.\\n        (total-due (+ (get amount current-loan-details) (unwrap-panic accrued-interest)))\\n        ;; Calculate the new loan total after borrowing additional amount.\\n        (new-loan (+ amount))\\n    )\\n        ;; Ensure the requested borrow amount does not exceed the allowed amount.\\n        (asserts! (<= new-loan allowed-borrow) err-overborrow)\\n        ;; Transfer the borrowed STX to the user.\\n        (let ((recipient tx-sender))\\n            (try! (as-contract (stx-transfer? amount tx-sender recipient)))\\n        )\\n        ;; Update the user\\'s loan details in the map.\\n        (map-set loans tx-sender { amount: new-loan, last-interaction-block: burn-block-height })\\n        ;; Return success.\\n        (ok true)\\n    )\\n)\\n\\n;; Read-only function to get the total balance by tx-sender\\n(define-read-only (get-balance-by-sender)\\n    (ok (map-get? deposits { owner: tx-sender }))\\n)\\n\\n;; Read-only function to get the total balance \\n(define-read-only (get-balance)\\n    (ok (var-get total-deposits))\\n)\\n\\n;; Read-only function to get the total amount owed by the user.\\n(define-read-only (get-amount-owed)\\n    (let (\\n        ;; Fetch current loan details or default to initial values.\\n        (current-loan-details (default-to { amount: u0, last-interaction-block: u0 } (map-get? loans tx-sender )))\\n        ;; Calculate accrued interest on the current loan.\\n        (accrued-interest (calculate-accrued-interest (get amount current-loan-details) (get last-interaction-block current-loan-details)))\\n        ;; Calculate the total amount due including interest.\\n        (total-due (+ (get amount current-loan-details) (unwrap-panic accrued-interest)))\\n    )\\n    ;; Return the total amount due.\\n    (ok total-due)\\n    )\\n)\\n\\n;; Public function for users to repay their STX loans.\\n(define-public (repay (amount uint))\\n    (let (\\n        ;; Fetch current loan details or default to initial values.\\n        (current-loan-details (default-to { amount: u0, last-interaction-block: u0 } (map-get? loans tx-sender )))\\n        ;; Calculate accrued interest since the last interaction.\\n        (accrued-interest (unwrap! (calculate-accrued-interest (get amount current-loan-details) (get last-interaction-block current-loan-details)) err-no-interest))\\n        ;; Calculate the total amount due including accrued interest.\\n        (total-due (+ (get amount current-loan-details) accrued-interest))\\n    )\\n        ;; Ensure the repayment amount is not more than the total due.\\n        (asserts! (>= total-due amount) err-overpay)\\n        ;; Transfer the repayment amount from the user to the contract.\\n        (try! (stx-transfer? amount tx-sender (as-contract tx-sender)))\\n        ;; Update the user\\'s loan details in the map with the new total due.\\n        (map-set loans tx-sender { amount: (- total-due amount), last-interaction-block: burn-block-height })\\n        ;; Update the pool reserve with the paid interest.\\n        (var-set pool-reserve (+ (var-get pool-reserve) accrued-interest))\\n        ;; Return success.\\n        (ok true)\\n    )\\n)\\n\\n;; Public function for users to claim their yield based on the pool reserve and their deposits.\\n(define-public (claim-yield)\\n    (let (\\n        ;; Fetch user\\'s deposit amount or default to 0.\\n        (user-deposit (default-to u0 (get amount (map-get? deposits { owner: tx-sender }))))\\n        ;; Calculate the yield amount based on user\\'s share of the pool.\\n        (yield-amount (/ (* (var-get pool-reserve) user-deposit) (var-get total-deposits)))\\n    )\\n        ;; Transfer the yield amount from the contract to the user.\\n        (let ((recipient tx-sender))\\n            (try! (as-contract (stx-transfer? yield-amount tx-sender recipient)))\\n        )\\n        ;; Update the pool reserve by subtracting the claimed yield.\\n        (var-set pool-reserve (- (var-get pool-reserve) yield-amount))\\n        ;; Return success.\\n        (ok true)\\n    )\\n)\\n\\n;; Private function to calculate the accrued interest on a loan.\\n(define-private (calculate-accrued-interest (principal uint) (start-block uint))\\n    (let (\\n        ;; Calculate the number of blocks elapsed since the last interaction.\\n        (elapsed-blocks (- burn-block-height start-block))\\n        ;; Calculate the interest based on the principal, rate, and elapsed time.\\n        (interest (/ (* principal (var-get loan-interest-rate) elapsed-blocks) u10000))\\n    )\\n        ;; Ensure the loan started in the past (not at block 0).\\n        (asserts! (not (is-eq start-block u0)) (ok u0))\\n        ;; Return the calculated interest.\\n       (ok interest)\\n    )\\n)<｜end▁of▁sentence｜>'"},"metadata":{}}],"execution_count":51},{"cell_type":"markdown","source":"## Step 3: Setting up the model using LoRA","metadata":{}},{"cell_type":"code","source":"# Apply LoRA (Low-Rank Adaptation) fine-tuning to the model \nmodel_lora = FastLanguageModel.get_peft_model(\n    model,\n    r=16,  # LoRA rank: Determines the size of the trainable adapters (higher = more parameters, lower = more efficiency)\n    target_modules=[  # List of transformer layers where LoRA adapters will be applied\n        \"q_proj\",   # Query projection in the self-attention mechanism\n        \"k_proj\",   # Key projection in the self-attention mechanism\n        \"v_proj\",   # Value projection in the self-attention mechanism\n        \"o_proj\",   # Output projection from the attention layer\n        \"gate_proj\",  # Used in feed-forward layers (MLP)\n        \"up_proj\",    # Part of the transformer’s feed-forward network (FFN)\n        \"down_proj\",  # Another part of the transformer’s FFN\n    ],\n    lora_alpha=16,  # Scaling factor for LoRA updates (higher values allow more influence from LoRA layers)\n    lora_dropout=0,  # Dropout rate for LoRA layers (0 means no dropout, full retention of information)\n    bias=\"none\",  # Specifies whether LoRA layers should learn bias terms (setting to \"none\" saves memory)\n    use_gradient_checkpointing=\"unsloth\",  # Saves memory by recomputing activations instead of storing them (recommended for long-context fine-tuning)\n    random_state=3407,  # Sets a seed for reproducibility, ensuring the same fine-tuning behavior across runs\n    use_rslora=False,  # Whether to use Rank-Stabilized LoRA (disabled here, meaning fixed-rank LoRA is used)\n    loftq_config=None,  # Low-bit Fine-Tuning Quantization (LoFTQ) is disabled in this configuration\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T04:07:43.838774Z","iopub.execute_input":"2025-03-14T04:07:43.839070Z","iopub.status.idle":"2025-03-14T04:07:49.977653Z","shell.execute_reply.started":"2025-03-14T04:07:43.839050Z","shell.execute_reply":"2025-03-14T04:07:49.976990Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.3.10 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# Initialize the fine-tuning trainer — Imported using from trl import SFTTrainer\ntrainer = SFTTrainer(\n    model=model_lora,  # The model to be fine-tuned\n    tokenizer=tokenizer,  # Tokenizer to process text inputs\n    train_dataset=dataset_finetune,  # Dataset used for training\n    dataset_text_field=\"text\",  # Specifies which field in the dataset contains training text\n    max_seq_length=max_seq_length,  # Defines the maximum sequence length for inputs\n    dataset_num_proc=2,  # Uses 2 CPU threads to speed up data preprocessing\n\n    # Define training arguments\n    args=TrainingArguments(\n        per_device_train_batch_size=2,  # Number of examples processed per device (GPU) at a time\n        gradient_accumulation_steps=4,  # Accumulate gradients over 4 steps before updating weights\n        num_train_epochs=1, # Full fine-tuning run\n        warmup_steps=5,  # Gradually increases learning rate for the first 5 steps\n        max_steps=60,  # Limits training to 60 steps (useful for debugging; increase for full fine-tuning)\n        learning_rate=2e-4,  # Learning rate for weight updates (tuned for LoRA fine-tuning)\n        fp16=not is_bfloat16_supported(),  # Use FP16 (if BF16 is not supported) to speed up training\n        bf16=is_bfloat16_supported(),  # Use BF16 if supported (better numerical stability on newer GPUs)\n        logging_steps=10,  # Logs training progress every 10 steps\n        optim=\"adamw_8bit\",  # Uses memory-efficient AdamW optimizer in 8-bit mode\n        weight_decay=0.01,  # Regularization to prevent overfitting\n        lr_scheduler_type=\"linear\",  # Uses a linear learning rate schedule\n        seed=3407,  # Sets a fixed seed for reproducibility\n        output_dir=\"outputs\",  # Directory where fine-tuned model checkpoints will be saved\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T04:12:11.178781Z","iopub.execute_input":"2025-03-14T04:12:11.179072Z","iopub.status.idle":"2025-03-14T04:12:13.803241Z","shell.execute_reply.started":"2025-03-14T04:12:11.179049Z","shell.execute_reply":"2025-03-14T04:12:13.802500Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/97 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1bca6932b8545eca9b9ed9fb62dfafa"}},"metadata":{}}],"execution_count":52},{"cell_type":"markdown","source":"# Step 4: Train the model","metadata":{}},{"cell_type":"code","source":"# Start the fine-tuning process\ntrainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T04:12:56.296048Z","iopub.execute_input":"2025-03-14T04:12:56.296384Z","iopub.status.idle":"2025-03-14T05:34:42.463789Z","shell.execute_reply.started":"2025-03-14T04:12:56.296358Z","shell.execute_reply":"2025-03-14T05:34:42.462927Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 97 | Num Epochs = 10 | Total steps = 60\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n \"-____-\"     Trainable parameters = 41,943,040/4,670,623,744 (0.90% trained)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 1:19:52, Epoch 8/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.928600</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.328500</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.024000</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.880900</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.774300</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.725600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:34:57.598487Z","iopub.execute_input":"2025-03-14T05:34:57.598801Z","iopub.status.idle":"2025-03-14T05:34:59.118855Z","shell.execute_reply.started":"2025-03-14T05:34:57.598767Z","shell.execute_reply":"2025-03-14T05:34:59.118265Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▂▄▅▇██</td></tr><tr><td>train/global_step</td><td>▁▂▄▅▇██</td></tr><tr><td>train/grad_norm</td><td>█▂▂▁▁▁</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>7.683926376517632e+16</td></tr><tr><td>train/epoch</td><td>8.64</td></tr><tr><td>train/global_step</td><td>60</td></tr><tr><td>train/grad_norm</td><td>0.25242</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>0.7256</td></tr><tr><td>train_loss</td><td>1.11032</td></tr><tr><td>train_runtime</td><td>4904.0981</td></tr><tr><td>train_samples_per_second</td><td>0.196</td></tr><tr><td>train_steps_per_second</td><td>0.012</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">cookies-n-cream-pastry-1</strong> at: <a href='https://wandb.ai/oriol_palacios-universidad-nacional-de-san-antonio-abad-/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Clarity%20Dataset%20for%20Clarity-AI-Agent/runs/swo4v5iy' target=\"_blank\">https://wandb.ai/oriol_palacios-universidad-nacional-de-san-antonio-abad-/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Clarity%20Dataset%20for%20Clarity-AI-Agent/runs/swo4v5iy</a><br> View project at: <a href='https://wandb.ai/oriol_palacios-universidad-nacional-de-san-antonio-abad-/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Clarity%20Dataset%20for%20Clarity-AI-Agent' target=\"_blank\">https://wandb.ai/oriol_palacios-universidad-nacional-de-san-antonio-abad-/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Clarity%20Dataset%20for%20Clarity-AI-Agent</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250314_033624-swo4v5iy/logs</code>"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"new_model_online = \"oriolpal/DeepSeek-R1-Clarity-AI-Agent\"\nnew_model_local = \"DeepSeek-R1-Clarity-AI-Agent\"\nmodel_lora.save_pretrained(new_model_local) # Local saving\ntokenizer.save_pretrained(new_model_local)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:49:01.880862Z","iopub.execute_input":"2025-03-14T05:49:01.881204Z","iopub.status.idle":"2025-03-14T05:49:02.592182Z","shell.execute_reply.started":"2025-03-14T05:49:01.881156Z","shell.execute_reply":"2025-03-14T05:49:02.591170Z"}},"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"('DeepSeek-R1-Clarity-AI-Agent/tokenizer_config.json',\n 'DeepSeek-R1-Clarity-AI-Agent/special_tokens_map.json',\n 'DeepSeek-R1-Clarity-AI-Agent/tokenizer.json')"},"metadata":{}}],"execution_count":69},{"cell_type":"markdown","source":"# Testing the fine tuned model","metadata":{}},{"cell_type":"code","source":"prompt_style = \"\"\"Below is an instruction describing a task. First analyze the technical requirements, then provide a secure Clarity-specific solution.\n\n### Instruction:\nYou are a Clarity blockchain engineer with 5+ years experience. Your answers must, follow Clarity's deterministic principles, prevent common vulnerabilities, use official documentation\n\n### Question:\n{}\n\n### Response:\n<think>\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:49:17.841901Z","iopub.execute_input":"2025-03-14T05:49:17.842227Z","iopub.status.idle":"2025-03-14T05:49:17.845908Z","shell.execute_reply.started":"2025-03-14T05:49:17.842169Z","shell.execute_reply":"2025-03-14T05:49:17.845091Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"import torch\n\nquestion = \"\"\"Create a Clarity smart contract on Stacks that retrieves real-time price data for a specific asset (e.g., BTC/USD) from the Pyth Network using the Stacks-Pyth Bridge. Include deployment and testing instructions.\"\"\"\n# Load the inference model using FastLanguageModel (Unsloth optimizes for speed)\nFastLanguageModel.for_inference(model_lora)  # Unsloth has 2x faster inference!\n\n# Set the torch dtype correctly\nmodel_lora.config.torch_dtype = torch.float16\n\n# Tokenize the input question with a specific prompt format and move it to the GPU\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\n# Generate a response using LoRA fine-tuned model with specific parameters\noutputs = model_lora.generate(\n    input_ids=inputs.input_ids,          # Tokenized input IDs\n    attention_mask=inputs.attention_mask, # Attention mask for padding handling\n    max_new_tokens=1200,                  # Maximum length for generated response\n    use_cache=True,                       # Enable cache for efficient generation\n)\n\n# Decode the generated response from tokenized format to readable text\nresponse = tokenizer.batch_decode(outputs)\n# Extract and print only the model's response part after \"### Response:\"\nprint(response[0].split(\"### Response:\")[1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:51:11.772104Z","iopub.execute_input":"2025-03-14T05:51:11.772455Z","iopub.status.idle":"2025-03-14T05:51:58.421560Z","shell.execute_reply.started":"2025-03-14T05:51:11.772431Z","shell.execute_reply":"2025-03-14T05:51:58.420739Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nThe objective is to create a Clarity smart contract on Stacks that fetches real-time price data for Bitcoin (BTC) against USD using the Pyth Network's oracle system. This entails interacting with the Pyth Oracle contract on Stacks and the Pyth Network's BTC/USD feed contract. The contract must handle the process of querying live price data, updating the contract's internal state, and allowing users to retrieve the price via a read-only function. Error handling is crucial, so both the oracle query and feed contract interaction must include error handling. The contract should also store the last price retrieved and the block height at which it was last updated. Security is paramount, so the contract must restrict access to specific addresses. The implementation should use traits like `pyth-trait` for the Pyth Oracle and `pyth-token-v1` for the BTC/USD feed. The `get-price` function will attempt to retrieve the price from the Pyth Oracle, then from the Pyth feed contract, and return the most recent price. If the retrieval fails, it should return `none`. The `update-price` function will allow authorized callers to update the price and block height, ensuring the contract's data is up-to-date. The `get-last-price` function will return the most recently stored price. The contract's deployment will require the user to initialize it with `contract-call?` and `as-contract` to prevent unauthorized calls.\n</think>\n;; pyth-oracle-price\n(use-trait pyth-trait 'SP2JXKMS3S3Q5K6Z5X6Y5Q5Q5Y5Q.pyth-traits-v1.pyth-trait)\n(use-trait pyth-token-v1 'SP3FBR2AGK5H9QBDH3EEN6DF8EK8JY7RX8QJ5SVTE.sip-010-trait)\n\n(define-constant contract-owner tx-sender)\n\n(define-constant err-u1000 (err u1000))\n(define-constant err-u2000 (err u2001))\n\n(define-constant contract-deployment-height u5400)\n(define-constant contract-deployment-hash (sha256 (as-concat \"pyth-oracle-price\" contract-deployment-height))))\n\n(define-data-var last-price (optional uint) none)\n(define-data-var last-block-height (optional uint) none)\n\n(define-read-only (get-price)\n    (let\n        (\n            (price (contract-call?\n                'PYTH-PAB-NODE-10 pyth-get-price\n                'SP3FBR2AGK5H9QBDH3EEN6DF8EK8JY7RX8QJ5SVTE.sip-010\n                0xe9a7a2c8afed59dfc2c85b8b26c1e5a3de42266b\n                (var-get last-block-height)\n            )\n            (err (unwrap! price err-u2000))\n        )\n        (ok price)\n    )\n)\n\n(define-public (update-price (price uint) (block-height uint))\n    (begin\n        (asserts! (is-eq tx-sender contract-owner) err-u1000)\n        (var-set last-price (some price))\n        (var-set last-block-height (some block-height))\n    )\n)\n\n(define-read-only (get-last-price)\n    (ok (var-get last-price))\n)<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":72},{"cell_type":"markdown","source":"# Pushing the model to HuggingFace","metadata":{}},{"cell_type":"code","source":"new_model_online = \"OriolPalacios/DeepSeek-R1-Clarity-AI-Agent\"\nmodel_lora.push_to_hub(new_model_online) # Online saving\ntokenizer.push_to_hub(new_model_online) # Online saving ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T05:57:35.978561Z","iopub.execute_input":"2025-03-14T05:57:35.978867Z","iopub.status.idle":"2025-03-14T05:57:42.086450Z","shell.execute_reply.started":"2025-03-14T05:57:35.978845Z","shell.execute_reply":"2025-03-14T05:57:42.085759Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/632 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46340d5ecf8f4713b779bc0df053d2d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05152007b7464fb5adde8d2bc7531bcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d78a36315e29479ab4b5f3d102aeace2"}},"metadata":{}},{"name":"stdout","text":"Saved model to https://huggingface.co/OriolPalacios/DeepSeek-R1-Clarity-AI-Agent\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"532dd0c18a2c4822a1af11da6a9021df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f4edec9c9014da19dab23b15349467b"}},"metadata":{}}],"execution_count":74}]}